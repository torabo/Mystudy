{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from visual import *\n",
    "# from plotter import *\n",
    "# from dataloader import load_data\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "np.random.seed(100)\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "'''\n",
    "1. 입력층과 출력층은 그대로 사용합니다.\n",
    "'''\n",
    "\n",
    "def Develop():\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "                  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                  tf.keras.layers.Dense(64, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(0.001)),\n",
    "                  tf.keras.layers.Dropout(0.1),\n",
    "                  tf.keras.layers.Dense(64, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(0.001)),\n",
    "                  tf.keras.layers.Dropout(0.1),\n",
    "                  tf.keras.layers.Dense(10, activation='softmax')\n",
    "                  ])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "'''\n",
    "2. 모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "   Step01. Develop 함수를 이용해 두 모델을 불러옵니다.\n",
    "   \n",
    "   Step02. 모델의 손실 함수, 최적화 알고리즘, 평가 방법을 설정합니다.\n",
    "   \n",
    "   Step03. 모델의 구조를 확인하는 코드를 작성합니다.\n",
    "   \n",
    "   Step04. 모델을 학습시킵니다. 두 모델 모두 'epochs'는 20,\n",
    "           'batch_size'는 500으로 설정합니다. 검증용 데이터도 설정해주세요.\n",
    "   \n",
    "   Step05. 모델을 테스트하고 accuracy 점수를 출력합니다. \n",
    "           모델의 성능을 확인해보고, 목표값을 달성해보세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Fashion-MNIST 데이터를 불러오고 전처리하는 부분입니다.\n",
    "    (train_images, train_labels), (test_images, test_labels) = load_data()\n",
    "    \n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    develop_model = Develop()\n",
    "    \n",
    "    develop_model.compile(loss = 'sparse_categorical_crossentropy' , \n",
    "    optimizer = 'adam' , \n",
    "    metrics = ['accuracy'])\n",
    "    \n",
    "    develop_model.summary()\n",
    "    \n",
    "    history = develop_model.fit(train_images, train_labels, epochs =20 , batch_size = 500, validation_data =(test_images, test_labels), verbose = 0)\n",
    "    \n",
    "    scores = develop_model.evaluate(test_images,test_labels)\n",
    "    \n",
    "    print('\\naccuracy_develop: ', scores[-1])\n",
    "    \n",
    "    Visulaize([('Develop', history)])\n",
    "    \n",
    "    return history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tora",
   "language": "python",
   "name": "tora"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
